{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GoogleNet(Inception_basic)- Transfer Learning.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"X5IseY1LQ1lr","colab_type":"text"},"source":["# Transfer Learning\n","\n","In this notebook, we'll use pre-trained networks to solved challenging problems in computer vision. Specifically, we'll use networks trained on [ImageNet](http://www.image-net.org/) [available from torchvision](http://pytorch.org/docs/0.3.0/torchvision/models.html). \n","\n","ImageNet is a massive dataset with over 1 million labeled images in 1000 categories. It's used to train a Convolutional neural network architechture. \n","\n","Once trained, these models work astonishingly well as feature detectors for images they weren't trained on.  we'll use transfer learning to train a network that can classify our cat and dog photos with near perfect accuracy.\n"]},{"cell_type":"code","metadata":{"id":"L-mTOXk8YcBk","colab_type":"code","outputId":"cbc780eb-287f-4ed0-d4c4-942df4c96f92","executionInfo":{"status":"ok","timestamp":1560552507926,"user_tz":300,"elapsed":28811,"user":{"displayName":"Gaurav Rai","photoUrl":"","userId":"02602739693383355123"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"V4CGWcaUYcXb","colab_type":"code","colab":{}},"source":["!unzip -q \"/gdrive/My Drive/Deep Learning with PyTorch/Cat_Dog_data.zip\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pliWG0n3Q1lu","colab_type":"code","colab":{}},"source":["%matplotlib inline\n","%config InlineBackend.figure_format = 'retina'\n","\n","import matplotlib.pyplot as plt\n","\n","import torch\n","from torch import nn\n","from torch import optim\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms, models"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j8kV7cphQ1l1","colab_type":"text"},"source":["The pretrained model which we are going to use requires the input to be 224x224 images. Also, we'll need to match the normalization used when the models were trained. Each color channel was normalized separately, the means are [0.485, 0.456, 0.406] and the standard deviations are [0.229, 0.224, 0.225]."]},{"cell_type":"code","metadata":{"id":"4ZhVgAG0Q1l3","colab_type":"code","colab":{}},"source":["data_dir = 'Cat_Dog_data'\n","\n","# Defining transforms for the training data and testing data\n","train_transforms = transforms.Compose([transforms.RandomRotation(30),\n","                                       transforms.RandomResizedCrop(224),\n","                                       transforms.RandomHorizontalFlip(),\n","                                       transforms.ToTensor(),\n","                                       transforms.Normalize([0.485, 0.456, 0.406],\n","                                                            [0.229, 0.224, 0.225])])\n","\n","test_transforms = transforms.Compose([transforms.Resize(255),\n","                                      transforms.CenterCrop(224),\n","                                      transforms.ToTensor(),\n","                                      transforms.Normalize([0.485, 0.456, 0.406],\n","                                                           [0.229, 0.224, 0.225])])\n","\n","# Passing transforms in here, then run the next cell to see how the transforms look\n","train_data = datasets.ImageFolder(data_dir + '/train', transform=train_transforms)\n","test_data = datasets.ImageFolder(data_dir + '/test', transform=test_transforms)\n","\n","trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n","testloader = torch.utils.data.DataLoader(test_data, batch_size=64)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Vo_7e47Zabme","colab_type":"text"},"source":["We will load in the GoogLeNet Model . Let's print out the model architecture so we can see what's going on."]},{"cell_type":"code","metadata":{"scrolled":true,"id":"4DWK0K8vQ1mD","colab_type":"code","outputId":"aef4773a-a9e1-4991-a029-dd775b312353","executionInfo":{"status":"ok","timestamp":1560552563924,"user_tz":300,"elapsed":3451,"user":{"displayName":"Gaurav Rai","photoUrl":"","userId":"02602739693383355123"}},"colab":{"base_uri":"https://localhost:8080/","height":5457}},"source":["model = models.googlenet(pretrained=True)\n","model"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/googlenet-1378be20.pth\" to /root/.cache/torch/checkpoints/googlenet-1378be20.pth\n","100%|██████████| 52147035/52147035 [00:02<00:00, 22009921.90it/s]\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["GoogLeNet(\n","  (conv1): BasicConv2d(\n","    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n","  (conv2): BasicConv2d(\n","    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (conv3): BasicConv2d(\n","    (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n","  (inception3a): Inception(\n","    (branch1): BasicConv2d(\n","      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch2): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch3): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch4): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","      (1): BasicConv2d(\n","        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (inception3b): Inception(\n","    (branch1): BasicConv2d(\n","      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch2): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch3): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch4): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","      (1): BasicConv2d(\n","        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n","  (inception4a): Inception(\n","    (branch1): BasicConv2d(\n","      (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch2): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch3): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch4): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","      (1): BasicConv2d(\n","        (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (inception4b): Inception(\n","    (branch1): BasicConv2d(\n","      (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch2): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch3): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch4): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","      (1): BasicConv2d(\n","        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (inception4c): Inception(\n","    (branch1): BasicConv2d(\n","      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch2): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch3): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch4): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","      (1): BasicConv2d(\n","        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (inception4d): Inception(\n","    (branch1): BasicConv2d(\n","      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch2): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch3): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch4): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","      (1): BasicConv2d(\n","        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (inception4e): Inception(\n","    (branch1): BasicConv2d(\n","      (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch2): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch3): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch4): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","      (1): BasicConv2d(\n","        (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n","  (inception5a): Inception(\n","    (branch1): BasicConv2d(\n","      (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch2): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch3): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch4): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","      (1): BasicConv2d(\n","        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (inception5b): Inception(\n","    (branch1): BasicConv2d(\n","      (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch2): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch3): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch4): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","      (1): BasicConv2d(\n","        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (dropout): Dropout(p=0.2)\n","  (fc): Linear(in_features=1024, out_features=1000, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"cqEpnqqrQ1mN","colab_type":"text"},"source":["This model is built out of two main parts, the features and the classifier. The features part is a stack of convolutional layers and overall works as a feature detector that can be fed into a classifier. The classifier part is a single fully-connected layer `(classifier): Linear(in_features=1024, out_features=1000)`. This layer was trained on the ImageNet dataset, so it won't work for our specific problem. That means we need to replace the classifier, but the features will work perfectly on their own. In general, I think about pre-trained networks as amazingly good feature detectors that can be used as the input for simple feed-forward classifiers."]},{"cell_type":"code","metadata":{"id":"YdZeEgcOQ1mP","colab_type":"code","colab":{}},"source":["# Freezing parameters so we don't backprop through them\n","for param in model.parameters():\n","    param.requires_grad = False\n","\n","from collections import OrderedDict\n","classifier = nn.Sequential(OrderedDict([\n","                          ('fc1', nn.Linear(1024, 500)),\n","                          ('relu', nn.ReLU()),\n","                          ('fc2', nn.Linear(500, 2)),\n","                          ('output', nn.LogSoftmax(dim=1))\n","                          ]))\n","    \n","model.fc = classifier"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DyNoeSWNQ1mY","colab_type":"text"},"source":["With our model built, we need to train the classifier. However, now we're using a **really deep** neural network. If you try to train this on a CPU like normal, it will take a long, long time. Instead, we're going to use the GPU to do the calculations. Training on GPU generally speeds up the training 100X.\n"]},{"cell_type":"code","metadata":{"id":"LQBlxvnYQ1ma","colab_type":"code","colab":{}},"source":["import time"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"T0h0QS40Q1mi","colab_type":"code","outputId":"8b8e2cd4-7916-42ba-e2ca-7e0449c42861","executionInfo":{"status":"ok","timestamp":1560552762486,"user_tz":300,"elapsed":41311,"user":{"displayName":"Gaurav Rai","photoUrl":"","userId":"02602739693383355123"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["for device in ['cpu','cuda']:\n","\n","    criterion = nn.NLLLoss()\n","    # Only train the classifier parameters, feature parameters are frozen\n","    optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n","\n","    model.to(device)\n","\n","    for ii, (inputs, labels) in enumerate(trainloader):\n","\n","        # Moving input and label tensors to the GPU\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        start = time.time()\n","\n","        outputs = model.forward(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        if ii==3:\n","            break\n","        \n","    print(f\"Device = {device}; Time per batch: {(time.time() - start)/3:.3f} seconds\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Device = cpu; Time per batch: 2.607 seconds\n","Device = cuda; Time per batch: 0.004 seconds\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Ot2FpAdTQ1mt","colab_type":"text"},"source":["\n","Training a pretrained models to classify the cat and dog images.  We will use  GoogLeNet in this notebook and try other architectures in the other notebooks of the repository."]},{"cell_type":"code","metadata":{"id":"HTh91DvsQ1mw","colab_type":"code","outputId":"8b077d6e-81fe-49bf-ae53-f35e36b76412","executionInfo":{"status":"ok","timestamp":1560554500568,"user_tz":300,"elapsed":1248165,"user":{"displayName":"Gaurav Rai","photoUrl":"","userId":"02602739693383355123"}},"colab":{"base_uri":"https://localhost:8080/","height":1207}},"source":["## Using a pretrained model to classify the cat and dog images\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # for using GPU if it's available\n","\n","model = models.googlenet(pretrained=True)\n","model\n","\n","# Freeze parameters so we don't backprop through them\n","for param in model.parameters():\n","    param.requires_grad = False\n","\n","from collections import OrderedDict\n","classifier = nn.Sequential(OrderedDict([\n","                          ('fc1', nn.Linear(1024, 500)),\n","                          ('relu', nn.ReLU()),\n","                          ('fc2', nn.Linear(500, 2)),\n","                          ('output', nn.LogSoftmax(dim=1))\n","                          ]))\n","    \n","model.fc = classifier\n","\n","criterion = nn.NLLLoss()\n","# Only train the classifier parameters, feature parameters are frozen\n","optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n","\n","model.to(device)\n","    \n","epochs = 1\n","steps = 0\n","running_loss = 0\n","print_every = 5\n","for epoch in range(epochs):\n","    for inputs, labels in trainloader:\n","        steps += 1\n","        # Moving input and label tensors to the default device\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        \n","        optimizer.zero_grad()\n","        \n","        logps = model.forward(inputs)\n","        loss = criterion(logps, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","        \n","        if steps % print_every == 0:\n","            test_loss = 0\n","            accuracy = 0\n","            model.eval()\n","            with torch.no_grad():\n","                for inputs, labels in testloader:\n","                    inputs, labels = inputs.to(device), labels.to(device)\n","                    logps = model.forward(inputs)\n","                    batch_loss = criterion(logps, labels)\n","                    \n","                    test_loss += batch_loss.item()\n","                    \n","                    # Calculating accuracy\n","                    ps = torch.exp(logps)\n","                    top_p, top_class = ps.topk(1, dim=1)\n","                    equals = top_class == labels.view(*top_class.shape)\n","                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n","                    \n","            print(f\"Batch-{steps/5}.. \"\n","                  f\"Train loss: {running_loss/print_every:.3f}.. \"\n","                  f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n","                  f\"Test accuracy: {accuracy/len(testloader):.3f}\")\n","            running_loss = 0\n","            model.train()\n","   "],"execution_count":0,"outputs":[{"output_type":"stream","text":["Batch-1.0.. Train loss: 0.567.. Test loss: 0.345.. Test accuracy: 0.859\n","Batch-2.0.. Train loss: 0.346.. Test loss: 0.154.. Test accuracy: 0.952\n","Batch-3.0.. Train loss: 0.309.. Test loss: 0.137.. Test accuracy: 0.945\n","Batch-4.0.. Train loss: 0.288.. Test loss: 0.098.. Test accuracy: 0.964\n","Batch-5.0.. Train loss: 0.219.. Test loss: 0.086.. Test accuracy: 0.968\n","Batch-6.0.. Train loss: 0.175.. Test loss: 0.095.. Test accuracy: 0.963\n","Batch-7.0.. Train loss: 0.232.. Test loss: 0.077.. Test accuracy: 0.971\n","Batch-8.0.. Train loss: 0.170.. Test loss: 0.071.. Test accuracy: 0.977\n","Batch-9.0.. Train loss: 0.184.. Test loss: 0.074.. Test accuracy: 0.974\n","Batch-10.0.. Train loss: 0.213.. Test loss: 0.071.. Test accuracy: 0.975\n","Batch-11.0.. Train loss: 0.207.. Test loss: 0.069.. Test accuracy: 0.975\n","Batch-12.0.. Train loss: 0.221.. Test loss: 0.066.. Test accuracy: 0.979\n","Batch-13.0.. Train loss: 0.189.. Test loss: 0.079.. Test accuracy: 0.971\n","Batch-14.0.. Train loss: 0.164.. Test loss: 0.083.. Test accuracy: 0.968\n","Batch-15.0.. Train loss: 0.177.. Test loss: 0.098.. Test accuracy: 0.964\n","Batch-16.0.. Train loss: 0.178.. Test loss: 0.065.. Test accuracy: 0.976\n","Batch-17.0.. Train loss: 0.175.. Test loss: 0.068.. Test accuracy: 0.975\n","Batch-18.0.. Train loss: 0.202.. Test loss: 0.065.. Test accuracy: 0.978\n","Batch-19.0.. Train loss: 0.272.. Test loss: 0.061.. Test accuracy: 0.979\n","Batch-20.0.. Train loss: 0.204.. Test loss: 0.069.. Test accuracy: 0.977\n","Batch-21.0.. Train loss: 0.205.. Test loss: 0.064.. Test accuracy: 0.980\n","Batch-22.0.. Train loss: 0.177.. Test loss: 0.092.. Test accuracy: 0.963\n","Batch-23.0.. Train loss: 0.199.. Test loss: 0.065.. Test accuracy: 0.979\n","Batch-24.0.. Train loss: 0.176.. Test loss: 0.064.. Test accuracy: 0.979\n","Batch-25.0.. Train loss: 0.193.. Test loss: 0.069.. Test accuracy: 0.975\n","Batch-26.0.. Train loss: 0.179.. Test loss: 0.068.. Test accuracy: 0.976\n","Batch-27.0.. Train loss: 0.188.. Test loss: 0.075.. Test accuracy: 0.971\n","Batch-28.0.. Train loss: 0.214.. Test loss: 0.066.. Test accuracy: 0.976\n","Batch-29.0.. Train loss: 0.155.. Test loss: 0.061.. Test accuracy: 0.979\n","Batch-30.0.. Train loss: 0.192.. Test loss: 0.094.. Test accuracy: 0.963\n","Batch-31.0.. Train loss: 0.228.. Test loss: 0.068.. Test accuracy: 0.975\n","Batch-32.0.. Train loss: 0.195.. Test loss: 0.064.. Test accuracy: 0.979\n","Batch-33.0.. Train loss: 0.187.. Test loss: 0.091.. Test accuracy: 0.964\n","Batch-34.0.. Train loss: 0.182.. Test loss: 0.061.. Test accuracy: 0.982\n","Batch-35.0.. Train loss: 0.145.. Test loss: 0.060.. Test accuracy: 0.979\n","Batch-36.0.. Train loss: 0.162.. Test loss: 0.060.. Test accuracy: 0.980\n","Batch-37.0.. Train loss: 0.177.. Test loss: 0.060.. Test accuracy: 0.977\n","Batch-38.0.. Train loss: 0.153.. Test loss: 0.059.. Test accuracy: 0.981\n","Batch-39.0.. Train loss: 0.142.. Test loss: 0.058.. Test accuracy: 0.979\n","Batch-40.0.. Train loss: 0.140.. Test loss: 0.067.. Test accuracy: 0.973\n","Batch-41.0.. Train loss: 0.136.. Test loss: 0.059.. Test accuracy: 0.980\n","Batch-42.0.. Train loss: 0.200.. Test loss: 0.059.. Test accuracy: 0.980\n","Batch-43.0.. Train loss: 0.232.. Test loss: 0.063.. Test accuracy: 0.976\n","Batch-44.0.. Train loss: 0.159.. Test loss: 0.060.. Test accuracy: 0.979\n","Batch-45.0.. Train loss: 0.189.. Test loss: 0.060.. Test accuracy: 0.979\n","Batch-46.0.. Train loss: 0.151.. Test loss: 0.058.. Test accuracy: 0.980\n","Batch-47.0.. Train loss: 0.175.. Test loss: 0.066.. Test accuracy: 0.976\n","Batch-48.0.. Train loss: 0.168.. Test loss: 0.092.. Test accuracy: 0.963\n","Batch-49.0.. Train loss: 0.199.. Test loss: 0.078.. Test accuracy: 0.971\n","Batch-50.0.. Train loss: 0.238.. Test loss: 0.089.. Test accuracy: 0.962\n","Batch-51.0.. Train loss: 0.226.. Test loss: 0.062.. Test accuracy: 0.979\n","Batch-52.0.. Train loss: 0.238.. Test loss: 0.061.. Test accuracy: 0.979\n","Batch-53.0.. Train loss: 0.186.. Test loss: 0.065.. Test accuracy: 0.982\n","Batch-54.0.. Train loss: 0.200.. Test loss: 0.065.. Test accuracy: 0.979\n","Batch-55.0.. Train loss: 0.209.. Test loss: 0.075.. Test accuracy: 0.976\n","Batch-56.0.. Train loss: 0.174.. Test loss: 0.063.. Test accuracy: 0.976\n","Batch-57.0.. Train loss: 0.120.. Test loss: 0.059.. Test accuracy: 0.980\n","Batch-58.0.. Train loss: 0.204.. Test loss: 0.060.. Test accuracy: 0.978\n","Batch-59.0.. Train loss: 0.131.. Test loss: 0.071.. Test accuracy: 0.972\n","Batch-60.0.. Train loss: 0.227.. Test loss: 0.063.. Test accuracy: 0.978\n","Batch-61.0.. Train loss: 0.298.. Test loss: 0.059.. Test accuracy: 0.977\n","Batch-62.0.. Train loss: 0.274.. Test loss: 0.128.. Test accuracy: 0.945\n","Batch-63.0.. Train loss: 0.220.. Test loss: 0.101.. Test accuracy: 0.963\n","Batch-64.0.. Train loss: 0.291.. Test loss: 0.072.. Test accuracy: 0.980\n","Batch-65.0.. Train loss: 0.223.. Test loss: 0.072.. Test accuracy: 0.977\n","Batch-66.0.. Train loss: 0.150.. Test loss: 0.063.. Test accuracy: 0.980\n","Batch-67.0.. Train loss: 0.145.. Test loss: 0.057.. Test accuracy: 0.981\n","Batch-68.0.. Train loss: 0.216.. Test loss: 0.059.. Test accuracy: 0.980\n","Batch-69.0.. Train loss: 0.222.. Test loss: 0.056.. Test accuracy: 0.981\n","Batch-70.0.. Train loss: 0.169.. Test loss: 0.056.. Test accuracy: 0.980\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hrLBH5i0Yla3","colab_type":"text"},"source":["Just like DenseNet, We have achieved an accuracy over 98% in just running one epoch to train the modified classifier of the GoogleNet. It is a pretty decent classification accuracy considering the fact that the training only took aboout an hour on my dell laptop having a 4 gb Nvidea GPU.\n","Had we trained the all the weights. it would have taken forever."]},{"cell_type":"code","metadata":{"id":"21ljzAmrYx6j","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}