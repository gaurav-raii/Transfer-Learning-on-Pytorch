{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ResNets- Transfer Learning .ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"1lcY6I347NQw","colab_type":"text"},"source":["# Transfer Learning\n","\n","In this notebook, we'll use pre-trained networks to solved challenging problems in computer vision. Specifically, we'll use networks trained on [ImageNet](http://www.image-net.org/) [available from torchvision](http://pytorch.org/docs/0.3.0/torchvision/models.html). \n","\n","ImageNet is a massive dataset with over 1 million labeled images in 1000 categories. It's used to train a Convolutional neural network architechture. \n","\n","Once trained, these models work astonishingly well as feature detectors for images they weren't trained on.  we'll use transfer learning to train a network that can classify our cat and dog photos with near perfect accuracy.\n"]},{"cell_type":"code","metadata":{"id":"1sEJtlGI3hjX","colab_type":"code","outputId":"ad5e01e7-e213-4047-9656-37f51e047396","executionInfo":{"status":"ok","timestamp":1560534705692,"user_tz":300,"elapsed":1954,"user":{"displayName":"Gaurav Rai","photoUrl":"","userId":"02602739693383355123"}},"colab":{"base_uri":"https://localhost:8080/","height":1720}},"source":["!cat  /proc/cpuinfo\n","!cat  /proc/meminfo"],"execution_count":0,"outputs":[{"output_type":"stream","text":["processor\t: 0\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2300.000\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 2\n","core id\t\t: 0\n","cpu cores\t: 1\n","apicid\t\t: 0\n","initial apicid\t: 0\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single pti ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf\n","bogomips\t: 4600.00\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 1\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2300.000\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 2\n","core id\t\t: 0\n","cpu cores\t: 1\n","apicid\t\t: 1\n","initial apicid\t: 1\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single pti ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf\n","bogomips\t: 4600.00\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","MemTotal:       13335276 kB\n","MemFree:        10997628 kB\n","MemAvailable:   12624500 kB\n","Buffers:           79344 kB\n","Cached:          1706500 kB\n","SwapCached:            0 kB\n","Active:           527560 kB\n","Inactive:        1529044 kB\n","Active(anon):     252584 kB\n","Inactive(anon):      348 kB\n","Active(file):     274976 kB\n","Inactive(file):  1528696 kB\n","Unevictable:           0 kB\n","Mlocked:               0 kB\n","SwapTotal:             0 kB\n","SwapFree:              0 kB\n","Dirty:              2232 kB\n","Writeback:             0 kB\n","AnonPages:        270692 kB\n","Mapped:           164096 kB\n","Shmem:               904 kB\n","Slab:             161744 kB\n","SReclaimable:     128384 kB\n","SUnreclaim:        33360 kB\n","KernelStack:        3920 kB\n","PageTables:         4588 kB\n","NFS_Unstable:          0 kB\n","Bounce:                0 kB\n","WritebackTmp:          0 kB\n","CommitLimit:     6667636 kB\n","Committed_AS:    1739856 kB\n","VmallocTotal:   34359738367 kB\n","VmallocUsed:           0 kB\n","VmallocChunk:          0 kB\n","AnonHugePages:         0 kB\n","ShmemHugePages:        0 kB\n","ShmemPmdMapped:        0 kB\n","HugePages_Total:       0\n","HugePages_Free:        0\n","HugePages_Rsvd:        0\n","HugePages_Surp:        0\n","Hugepagesize:       2048 kB\n","DirectMap4k:       92148 kB\n","DirectMap2M:     4102144 kB\n","DirectMap1G:    11534336 kB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NOH1eBha7SIY","colab_type":"code","outputId":"b10c588e-d0b5-4eb7-acea-9fb3534d9343","executionInfo":{"status":"ok","timestamp":1560555409651,"user_tz":300,"elapsed":39253,"user":{"displayName":"Gaurav Rai","photoUrl":"","userId":"02602739693383355123"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XrR59SN4Zjdh","colab_type":"code","colab":{}},"source":["!unzip -q \"/gdrive/My Drive/Deep Learning with PyTorch/Cat_Dog_data.zip\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vhNl8mqr7NQy","colab_type":"code","colab":{}},"source":["%matplotlib inline\n","%config InlineBackend.figure_format = 'retina'\n","\n","import matplotlib.pyplot as plt\n","\n","import torch\n","from torch import nn\n","from torch import optim\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms, models"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JS4B5JvV7NQ2","colab_type":"text"},"source":["he pretrained model which we are going to use requires the input to be 224x224 images. Also, we'll need to match the normalization used when the models were trained. Each color channel was normalized separately, the means are [0.485, 0.456, 0.406] and the standard deviations are [0.229, 0.224, 0.225]."]},{"cell_type":"code","metadata":{"id":"iXD6jThE7NQ3","colab_type":"code","colab":{}},"source":["data_dir = 'Cat_Dog_data'\n","\n","# Defining transforms for the training data and testing data\n","train_transforms = transforms.Compose([transforms.RandomRotation(30),\n","                                       transforms.RandomResizedCrop(224),\n","                                       transforms.RandomHorizontalFlip(),\n","                                       transforms.ToTensor(),\n","                                       transforms.Normalize([0.485, 0.456, 0.406],\n","                                                            [0.229, 0.224, 0.225])])\n","\n","test_transforms = transforms.Compose([transforms.Resize(255),\n","                                      transforms.CenterCrop(224),\n","                                      transforms.ToTensor(),\n","                                      transforms.Normalize([0.485, 0.456, 0.406],\n","                                                           [0.229, 0.224, 0.225])])\n","\n","# Passing transforms in here, then run the next cell to see how the transforms look\n","train_data = datasets.ImageFolder(data_dir + '/train', transform=train_transforms)\n","test_data = datasets.ImageFolder(data_dir + '/test', transform=test_transforms)\n","\n","trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n","testloader = torch.utils.data.DataLoader(test_data, batch_size=64)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sR7qeS5_7NQ5","colab_type":"text"},"source":["We will load in the Resnet Model . Let's print out the model architecture so we can see what's going on."]},{"cell_type":"code","metadata":{"scrolled":true,"id":"MK2uX_7P7NQ6","colab_type":"code","outputId":"ff4cff2a-5953-4e6e-da2c-e58963350f57","executionInfo":{"status":"ok","timestamp":1560555429006,"user_tz":300,"elapsed":7228,"user":{"displayName":"Gaurav Rai","photoUrl":"","userId":"02602739693383355123"}},"colab":{"base_uri":"https://localhost:8080/","height":2431}},"source":["model = models.resnet34(pretrained=True)\n","model"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.cache/torch/checkpoints/resnet34-333f7ec4.pth\n","100%|██████████| 87306240/87306240 [00:00<00:00, 96336754.15it/s]\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (2): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (2): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (3): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (2): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (3): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (4): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (5): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (2): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"6XoBmwPl7NQ8","colab_type":"text"},"source":["This model is built out of two main parts, the features and the classifier. The features part is a stack of convolutional layers and overall works as a feature detector that can be fed into a classifier. The classifier part is a single fully-connected layer `(classifier): Linear(in_features=1024, out_features=1000)`. This layer was trained on the ImageNet dataset, so it won't work for our specific problem. That means we need to replace the classifier, but the features will work perfectly on their own. In general, I think about pre-trained networks as amazingly good feature detectors that can be used as the input for simple feed-forward classifiers."]},{"cell_type":"code","metadata":{"id":"YUn3eDlW7NQ9","colab_type":"code","colab":{}},"source":["# Freezing the parameters so we don't backprop through them\n","for param in model.parameters():\n","    param.requires_grad = False\n","\n","from collections import OrderedDict\n","classifier = nn.Sequential(OrderedDict([\n","                          ('fc', nn.Linear(512, 2)),              \n","                          ('output', nn.LogSoftmax(dim=1))\n","                          ]))\n","    \n","model.fc = classifier"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hvaAJKCM7NRA","colab_type":"text"},"source":["With our model built, we need to train the classifier. However, now we're using a **really deep** neural network. If you try to train this on a CPU like normal, it will take a long, long time. Instead, we're going to use the GPU to do the calculations. Training on GPU generally speeds up the training 100X.\n"]},{"cell_type":"code","metadata":{"id":"FT3Rz7sb7NRA","colab_type":"code","colab":{}},"source":["import time"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8lLsPvPQ7NRD","colab_type":"code","outputId":"825d9153-ee28-490c-8c40-4f43720ccb65","executionInfo":{"status":"ok","timestamp":1560555473818,"user_tz":300,"elapsed":48019,"user":{"displayName":"Gaurav Rai","photoUrl":"","userId":"02602739693383355123"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["for device in ['cpu', 'cuda']:\n","\n","    criterion = nn.NLLLoss()\n","    # Only train the classifier parameters, feature parameters are frozen\n","    optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n","\n","    model.to(device)\n","\n","    for ii, (inputs, labels) in enumerate(trainloader):\n","\n","        # Move input and label tensors to the GPU\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        start = time.time()\n","\n","        outputs = model.forward(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        if ii==3:\n","            break\n","        \n","    print(f\"Device = {device}; Time per batch: {(time.time() - start)/3:.3f} seconds\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Device = cpu; Time per batch: 3.046 seconds\n","Device = cuda; Time per batch: 0.003 seconds\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NPritxsj7NRG","colab_type":"code","colab":{}},"source":["# Use GPU if it's available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","model = models.resnet34(pretrained=True)\n","\n","# Freezing parameters so we don't backprop through them\n","for param in model.parameters():\n","    param.requires_grad = False\n","    \n","from collections import OrderedDict\n","classifier = nn.Sequential(OrderedDict([\n","                          ('fc', nn.Linear(512, 2)),              \n","                          ('output', nn.LogSoftmax(dim=1))\n","                          ]))\n","    \n","model.fc = classifier\n","\n","criterion = nn.NLLLoss()\n","\n","# Only training the classifier parameters, feature parameters are frozen\n","optimizer = optim.Adam(model.fc.parameters(), lr=0.003)\n","\n","model.to(device);"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AsXbpfal7NRJ","colab_type":"code","outputId":"4dd3f13d-8fa8-4d6c-c70b-4a3343e0cd52","executionInfo":{"status":"ok","timestamp":1560537479813,"user_tz":300,"elapsed":1602169,"user":{"displayName":"Gaurav Rai","photoUrl":"","userId":"02602739693383355123"}},"colab":{"base_uri":"https://localhost:8080/","height":663}},"source":["epochs = 1\n","steps = 0\n","running_loss = 0\n","print_every = 5\n","for epoch in range(epochs):\n","    for inputs, labels in trainloader:\n","        steps += 1\n","        # Moving input and label tensors to the default device\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        \n","        optimizer.zero_grad()\n","        \n","        logps = model.forward(inputs)\n","        loss = criterion(logps, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","        \n","        if steps % print_every == 0:\n","            test_loss = 0\n","            accuracy = 0\n","            model.eval()\n","            with torch.no_grad():\n","                for inputs, labels in testloader:\n","                    inputs, labels = inputs.to(device), labels.to(device)\n","                    logps = model.forward(inputs)\n","                    batch_loss = criterion(logps, labels)\n","                    \n","                    test_loss += batch_loss.item()\n","                    \n","                    # Calculating accuracy\n","                    ps = torch.exp(logps)\n","                    top_p, top_class = ps.topk(1, dim=1)\n","                    equals = top_class == labels.view(*top_class.shape)\n","                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n","                    \n","            print(f\"Batch {steps/5}.. \"\n","                  f\"Train loss: {running_loss/print_every:.3f}.. \"\n","                  f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n","                  f\"Test accuracy: {accuracy/len(testloader):.3f}\")\n","            running_loss = 0\n","            model.train()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Batch 1.0.. Train loss: 0.839.. Test loss: 0.521.. Test accuracy: 0.678\n","Batch 2.0.. Train loss: 0.489.. Test loss: 0.270.. Test accuracy: 0.937\n","Batch 3.0.. Train loss: 0.327.. Test loss: 0.245.. Test accuracy: 0.915\n","Batch 4.0.. Train loss: 0.312.. Test loss: 0.140.. Test accuracy: 0.965\n","Batch 5.0.. Train loss: 0.293.. Test loss: 0.126.. Test accuracy: 0.963\n","Batch 6.0.. Train loss: 0.230.. Test loss: 0.126.. Test accuracy: 0.960\n","Batch 7.0.. Train loss: 0.219.. Test loss: 0.106.. Test accuracy: 0.968\n","Batch 8.0.. Train loss: 0.181.. Test loss: 0.096.. Test accuracy: 0.972\n","Batch 9.0.. Train loss: 0.195.. Test loss: 0.090.. Test accuracy: 0.969\n","Batch 10.0.. Train loss: 0.171.. Test loss: 0.085.. Test accuracy: 0.973\n","Batch 11.0.. Train loss: 0.217.. Test loss: 0.080.. Test accuracy: 0.972\n","Batch 12.0.. Train loss: 0.220.. Test loss: 0.088.. Test accuracy: 0.965\n","Batch 13.0.. Train loss: 0.206.. Test loss: 0.075.. Test accuracy: 0.977\n","Batch 14.0.. Train loss: 0.216.. Test loss: 0.080.. Test accuracy: 0.970\n","Batch 15.0.. Train loss: 0.257.. Test loss: 0.069.. Test accuracy: 0.979\n","Batch 16.0.. Train loss: 0.170.. Test loss: 0.078.. Test accuracy: 0.977\n","Batch 17.0.. Train loss: 0.144.. Test loss: 0.074.. Test accuracy: 0.972\n","Batch 18.0.. Train loss: 0.213.. Test loss: 0.063.. Test accuracy: 0.978\n","Batch 19.0.. Train loss: 0.185.. Test loss: 0.077.. Test accuracy: 0.977\n","Batch 20.0.. Train loss: 0.170.. Test loss: 0.065.. Test accuracy: 0.975\n","Batch 21.0.. Train loss: 0.182.. Test loss: 0.062.. Test accuracy: 0.978\n","Batch 22.0.. Train loss: 0.226.. Test loss: 0.081.. Test accuracy: 0.977\n","Batch 23.0.. Train loss: 0.158.. Test loss: 0.071.. Test accuracy: 0.971\n","Batch 24.0.. Train loss: 0.188.. Test loss: 0.057.. Test accuracy: 0.979\n","Batch 25.0.. Train loss: 0.139.. Test loss: 0.067.. Test accuracy: 0.980\n","Batch 26.0.. Train loss: 0.184.. Test loss: 0.060.. Test accuracy: 0.977\n","Batch 27.0.. Train loss: 0.159.. Test loss: 0.055.. Test accuracy: 0.979\n","Batch 28.0.. Train loss: 0.162.. Test loss: 0.055.. Test accuracy: 0.982\n","Batch 29.0.. Train loss: 0.138.. Test loss: 0.052.. Test accuracy: 0.981\n","Batch 30.0.. Train loss: 0.161.. Test loss: 0.053.. Test accuracy: 0.980\n","Batch 31.0.. Train loss: 0.169.. Test loss: 0.052.. Test accuracy: 0.981\n","Batch 32.0.. Train loss: 0.195.. Test loss: 0.051.. Test accuracy: 0.981\n","Batch 33.0.. Train loss: 0.161.. Test loss: 0.050.. Test accuracy: 0.982\n","Batch 34.0.. Train loss: 0.172.. Test loss: 0.054.. Test accuracy: 0.981\n","Batch 35.0.. Train loss: 0.151.. Test loss: 0.052.. Test accuracy: 0.984\n","Batch 36.0.. Train loss: 0.171.. Test loss: 0.055.. Test accuracy: 0.978\n","Batch 37.0.. Train loss: 0.143.. Test loss: 0.051.. Test accuracy: 0.980\n","Batch 38.0.. Train loss: 0.177.. Test loss: 0.055.. Test accuracy: 0.981\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3JQgPWZfbRE_","colab_type":"text"},"source":["Just like DenseNet and GoogLeNet in our previous notebooks of the repository We have achieved an accuracy over 98% in just running one epoch to train the modified classifier of the Resnet. It is a pretty decent classification accuracy considering the fact that the training only took aboout an hour on my dell laptop having a 4 gb Nvidea GPU.\n","Had we trained the all the weights. it would have taken forever."]},{"cell_type":"code","metadata":{"id":"60LCW2tNbSIl","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}